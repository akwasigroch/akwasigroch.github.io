<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Arkadiusz Kwasigroch</title>
    <link>https://akwasigroch.github.io/</link>
      <atom:link href="https://akwasigroch.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Arkadiusz Kwasigroch</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Arkadiusz Kwasigroch © 2020</copyright><lastBuildDate>Mon, 10 Feb 2020 18:00:00 +0000</lastBuildDate>
    <image>
      <url>https://akwasigroch.github.io/images/icon_huf19dda8888b9106de6dc6f7c8ef8bbc9_17545_512x512_fill_lanczos_center_2.png</url>
      <title>Arkadiusz Kwasigroch</title>
      <link>https://akwasigroch.github.io/</link>
    </image>
    
    <item>
      <title>Self-supervised learning in computer vision</title>
      <link>https://akwasigroch.github.io/talk/selfsupervised_ml_gdansk/</link>
      <pubDate>Mon, 10 Feb 2020 18:00:00 +0000</pubDate>
      <guid>https://akwasigroch.github.io/talk/selfsupervised_ml_gdansk/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learn probabilistic PCA first to better understand Variational Autoencoders</title>
      <link>https://akwasigroch.github.io/post/blog/probabilistic-pca/</link>
      <pubDate>Wed, 05 Feb 2020 22:38:09 +0100</pubDate>
      <guid>https://akwasigroch.github.io/post/blog/probabilistic-pca/</guid>
      <description>&lt;p&gt;I prepare a presentation on Variational Autoencoders to my university colleagues. I think what can help them understand the topic better. I noticed that a derivation of the loss function can  cause problems as it requires understanding and intuition of probabilistic concepts.&lt;/p&gt;
&lt;p&gt;I think that understanding probabilistic PCA first helps to understand Variational Autoencoders faster. Probabilistic PCA is a great and simple algorithm. The big advantage of this algorithm is that all the probability distributions used in the algorithm are Gaussian distributions. So starting from the latent variable distribution $p(z)$ and distribution of observed variables conditioned on latent variable $p(x|z)$, we can easily obtain the distribution of observed variable $p(x)$, and posterior distribution $p(z|x)$. It could be obtained analytically by known equations. What&#39;s more, we can easily sample from that distribution using known libraries like Numpy or Scipy. So to gain the intuition for this algorithm, it is worth to play with the examples. From my experience, learning probabilistic PCA makes learning Variational Autoencoders much easier, because I started to &amp;ldquo;feel&amp;rdquo; the equations.&lt;/p&gt;
&lt;p&gt;I prepared the short implementation of the probabilistic PCA method. I plan to show the code to listeners on my presentation to make the algorithm easier to understand. I hope that it also helps you. The code is available at my Github:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/akwasigroch/probabilistic_pca&#34;&gt;https://github.com/akwasigroch/probabilistic_pca&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I plan to prepare longer text on my blog concerning that method.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The first edition of Fundamentals of Data Science - Gdańsk</title>
      <link>https://akwasigroch.github.io/post/courses/first_edition/</link>
      <pubDate>Tue, 14 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://akwasigroch.github.io/post/courses/first_edition/</guid>
      <description>&lt;p&gt;The data science is a hot topic now, so along with &lt;a href=&#34;http://sharktime.com/en_About.html&#34;&gt;Piotr Chlebek&lt;/a&gt; and &lt;a href=&#34;https://codeme.pl/&#34;&gt;CODE:ME&lt;/a&gt; foundation we decided to organize a data science course. The course took place on 11-12.01.2020 in Gdańsk. The number of participants was limited, and the list of participants was full long before the date of the course. This shows a huge interest in data science and machine learning. The participants represented different professions, so it was a very interesting experience to teach them. During the course, there were many interesting discussions and great ideas about data science methods.&lt;/p&gt;
&lt;p&gt;The scope of the course was very wide and the participants had an opportunity to learn the fundamentals of data science and machine learning, as well as the tools used in those areas.
My part of the course includes the basics of data science tools and algorithms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Anaconda and Jupyter&lt;/li&gt;
&lt;li&gt;Numpy and Pandas&lt;/li&gt;
&lt;li&gt;Matplotlib and Seaborn&lt;/li&gt;
&lt;li&gt;Scikit-learn and Keras&lt;/li&gt;
&lt;li&gt;Classification, Regression, Clusterization&lt;/li&gt;
&lt;li&gt;Time series analysis&lt;/li&gt;
&lt;li&gt;Neural networks&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The teaching materials was based on the data gathered from &lt;a href=&#34;https://dane.gov.pl/&#34;&gt;https://dane.gov.pl/&lt;/a&gt;. The page provides great datasets that are very useful to teach the basics of data preparation, visualization and so on. Moreover, the use of these data is much more fun! For example, this is much more interesting to predict the number of passengers in public transport in the home city than analyzing the iris dataset.&lt;/p&gt;
&lt;p&gt;Another issue tackled by the participants was the analyze of football players from the FIFA game series. We were able to train the Support Vector Regression to predict the value of the players on the transfer market based on the rate of their skills like agility, strength etc. The obtained results were quite good. The problem was also validated on neural network, that performed even better.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The next edition of the course will take place soon.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Links to the course pages. The information about the feature courses will be provided there:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.sharktime.com/pl_KursDataScienceOdPodstaw.html&#34;&gt;http://www.sharktime.com/pl_KursDataScienceOdPodstaw.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://codeme.pl/data-science/&#34;&gt;https://codeme.pl/data-science/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Neural Architecture Search for Skin Lesion Classification</title>
      <link>https://akwasigroch.github.io/publication/neural_architecture_search_ieee/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://akwasigroch.github.io/publication/neural_architecture_search_ieee/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Deep neural network architecture search using network morphism</title>
      <link>https://akwasigroch.github.io/publication/neural_architecture_search_mmar/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://akwasigroch.github.io/publication/neural_architecture_search_mmar/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Selected technical issues of deep neural networks for image classification purposes</title>
      <link>https://akwasigroch.github.io/publication/technical_issues/</link>
      <pubDate>Fri, 01 Feb 2019 00:00:00 +0000</pubDate>
      <guid>https://akwasigroch.github.io/publication/technical_issues/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Diagnosis of Malignant Melanoma by Neural Network Ensemble-Based System Utilising Hand-Crafted Skin Lesion Features</title>
      <link>https://akwasigroch.github.io/publication/diagnosis_of_malignant_melanoma/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://akwasigroch.github.io/publication/diagnosis_of_malignant_melanoma/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Deep CNN based decision support system for detection and assessing the stage of diabetic retinopathy</title>
      <link>https://akwasigroch.github.io/publication/diabetic_retinopathy/</link>
      <pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://akwasigroch.github.io/publication/diabetic_retinopathy/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://akwasigroch.github.io/home/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://akwasigroch.github.io/home/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
